{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905cc01b-7edb-41fc-a71e-8194c8193380",
   "metadata": {},
   "source": [
    "# ChatBot RAG com documentos PDF\n",
    "---\n",
    "Este notebook cria uma classe chatbot com memoria para interagir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d115cc-453c-4ab3-b75f-22467f097548",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a9b4c9-45b0-48a8-9b2e-827275d55a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "## Groq\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "## core\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5080a9b-a2ba-467d-abff-7e6ff9404f90",
   "metadata": {},
   "source": [
    "### CONFIGURAÇÃO DA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f66fb9-0360-4919-a6f6-562d7b48963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key configurada!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY não foi configurada!\")\n",
    "\n",
    "print(\"API Key configurada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe165f46-9132-4d43-b60e-468889f65e44",
   "metadata": {},
   "source": [
    "### CONFIGURAÇÕES GLOBAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d06873-4c4d-4b2e-b355-a233626209a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CONFIGURAÇÕES\n",
      "    - Modelo LLM              - llama-3.1-8b-instant\n",
      "    - Temperatura             - 0.1\n",
      "    - Max tokens              - 2048\n",
      "    - Max mensagens histórico - 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CONFIGS = {\n",
    "    \"model\":\"llama-3.1-8b-instant\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_tokens\": 2048,\n",
    "    \"max_messages\":10\n",
    "}\n",
    "\n",
    "print(f\"\"\"\n",
    "CONFIGURAÇÕES\n",
    "    - Modelo LLM              - {CONFIGS['model']}\n",
    "    - Temperatura             - {CONFIGS['temperature']}\n",
    "    - Max tokens              - {CONFIGS['max_tokens']}\n",
    "    - Max mensagens histórico - {CONFIGS['max_messages']}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314a65f-955a-4449-b1f6-4ed164ed2fe8",
   "metadata": {},
   "source": [
    "### FUNÇÕES AUXILIARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b91abfb-2fbe-4e9e-8e7c-ce5ac44179d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check conexão\n",
    "def test_groq_connection() -> bool:\n",
    "    \"\"\"Testa a conexão com a API Groq.\"\"\"\n",
    "    try:\n",
    "        llm = ChatGroq(\n",
    "            model=CONFIGS['model'],\n",
    "            temperature=0,\n",
    "            api_key=GROQ_API_KEY\n",
    "        )\n",
    "        res = llm.invoke('Responda apenas: OK')\n",
    "        if res.content.strip().upper() == 'OK':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f'Erro: {str(e)}')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97087a-81c1-4a3a-92e8-1bce85e946d9",
   "metadata": {},
   "source": [
    "### CLASSE PRINCIPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9acef7df-38fc-4fd9-b000-139e38168d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    \"\"\"\n",
    "    ChatBot para conversar através da API Groq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs:Dict[str,Any]=CONFIGS):\n",
    "        \"\"\"Inicializa o chatbot\"\"\"\n",
    "        self.configs = configs\n",
    "        self.llm = None\n",
    "        self.history:List[Any] = []\n",
    "\n",
    "        print('=== INICIALIZANDO CHATBOT ===')\n",
    "        self._initialize_llm()\n",
    "        self._initialize_system_prompt()\n",
    "\n",
    "    def _initialize_llm(self):\n",
    "        \"\"\"Inicializa o modelo de linguagem Groq\"\"\"\n",
    "        self.llm = ChatGroq(\n",
    "            model=self.configs['model'],\n",
    "            temperature=self.configs['temperature'],\n",
    "            max_tokens=self.configs['max_tokens'],\n",
    "            api_key=GROQ_API_KEY\n",
    "        )\n",
    "        print(f'Modelo {self.configs[\"model\"]} carregado!')\n",
    "\n",
    "    def _initialize_system_prompt(self):\n",
    "        \"\"\"Mensagem Fixa\"\"\"\n",
    "        system_message = SystemMessage(\n",
    "            content='Você é um assistente prestativo que responde perguntas objetivamente.'\n",
    "        )\n",
    "        self.history.append(system_message)\n",
    "\n",
    "    def chat(self, user_input, verbose=True):\n",
    "        \"\"\"Processa um pergunta do usuário e retorna a resposta\"\"\"\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.history.append(HumanMessage(content=user_input))\n",
    "        res = self.llm.invoke(self.history)\n",
    "        self.history.append(AIMessage(content=res.content))\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        if len(self.history)>self.configs['max_messages']:\n",
    "            self.history = self.history[-self.configs['max_messages']:]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'USER: {user_input}\\n')\n",
    "            print(f'BOT: {res.content}\\nTime: {elapsed_time:2f}s')\n",
    "            print(f'\\n\\nHistorico: {len(self.history)}')\n",
    "        else:\n",
    "            print(res.content)\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Limpa o histórico de conversação\"\"\"\n",
    "        self.history = []\n",
    "        print('Histórico limpo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f9d4e-ee96-47d8-b37a-453f4785631c",
   "metadata": {},
   "source": [
    "### INICIALIZAR CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0518d7-c63d-44ca-befb-a2ff143cb49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIALIZANDO CHATBOT ===\n",
      "Modelo llama-3.1-8b-instant carregado!\n"
     ]
    }
   ],
   "source": [
    "if test_groq_connection():\n",
    "    bot = ChatBot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658f091-effd-4d22-a1ff-128352526446",
   "metadata": {},
   "source": [
    "### FAZER PERGUNTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb74eee2-77d4-43ee-8def-6979b99c6a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: Qual a capital da França\n",
      "\n",
      "BOT: A capital da França é Paris.\n",
      "Time: 0.210154s\n",
      "\n",
      "\n",
      "Historico: 3\n"
     ]
    }
   ],
   "source": [
    "bot.chat('Qual a capital da França')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af87810-b67f-4303-b2af-2025a7c84f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: Resuma econometria em uma frase.\n",
      "\n",
      "BOT: A econometria é a aplicação de métodos estatísticos e matemáticos para analisar e prever comportamentos econômicos, ajudando a tomar decisões informadas em áreas como política econômica, finanças e planejamento.\n",
      "Time: 0.275094s\n",
      "\n",
      "\n",
      "Historico: 5\n"
     ]
    }
   ],
   "source": [
    "bot.chat('Resuma econometria em uma frase.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a336456-1db0-413c-9a1c-39af3d7f908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em reinos de dados, onde informações se escondem,\n",
      "Um novo rei surge, com poderes mágicos adornados.\n",
      "Seu nome é Machine Learning, uma arte sublime,\n",
      "Que ajuda a prever, a classificar e a encontrar o tempo.\n",
      "\n",
      "Com algoritmos que aprendem, e ajustam-se ao passo,\n",
      "Ele analisa os dados, e descobre o que é preciso.\n",
      "A partir de exemplos, ele constrói regras e leis,\n",
      "Para prever o futuro, e evitar surpresas ruins.\n",
      "\n",
      "Ele é treinado com dados, que são alimentados e purificados,\n",
      "E a partir deles, ele aprende a reconhecer padrões e nuances.\n",
      "Com cada nova entrada, ele ajusta seu modelo,\n",
      "E se torna mais preciso, em sua previsão e classificação.\n",
      "\n",
      "Mas não é apenas prever, que é o seu poder,\n",
      "Ele também pode ajudar a encontrar soluções, e a melhorar.\n",
      "Com análises avançadas, ele pode identificar problemas,\n",
      "E sugerir soluções, que sejam eficazes e eficientes.\n",
      "\n",
      "Então, Machine Learning é um poderoso aliado,\n",
      "Que ajuda a tomar decisões, com base em dados e fatos.\n",
      "Ele é uma ferramenta valiosa, que pode ser usada,\n",
      "Para melhorar a vida das pessoas, e a economia, em geral.\n"
     ]
    }
   ],
   "source": [
    "bot.chat('Explique machine learning em forma de poema',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97a3c74e-b097-4ebc-bb8c-811c74bd7a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: resuma em uma frase: o que sao demonstrações financeiras na contabilidade?\n",
      "\n",
      "BOT: As demonstrações financeiras são relatórios que apresentam a situação financeira e o desempenho de uma empresa, incluindo o balanço patrimonial, o resultado do exercício e o fluxo de caixa, com o objetivo de fornecer informações precisas e confiáveis sobre a empresa.\n",
      "Time: 0.386994s\n",
      "\n",
      "\n",
      "Historico: 9\n"
     ]
    }
   ],
   "source": [
    "bot.chat('resuma em uma frase: o que sao demonstrações financeiras na contabilidade?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aac7114-f46c-4184-b25e-d0a35af2a573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: qual foi minha primeira pergunta?\n",
      "\n",
      "BOT: Sua primeira pergunta foi sobre a capital da França.\n",
      "Time: 0.236057s\n",
      "\n",
      "\n",
      "Historico: 10\n"
     ]
    }
   ],
   "source": [
    "bot.chat('qual foi minha primeira pergunta?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf0a3c9-2450-4fc3-a404-000a689e0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histórico limpo\n"
     ]
    }
   ],
   "source": [
    "bot.clear_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8e4b24c-53d0-4d7a-8471-5f76741f9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: qual foi minha primeira pergunta?\n",
      "\n",
      "BOT: Sua primeira pergunta foi: \"qual foi minha primeira pergunta?\"\n",
      "Time: 0.219652s\n",
      "\n",
      "\n",
      "Historico: 2\n"
     ]
    }
   ],
   "source": [
    "bot.chat('qual foi minha primeira pergunta?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
